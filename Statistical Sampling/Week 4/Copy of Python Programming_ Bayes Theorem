{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Python Programming: Bayes Theorem","provenance":[{"file_id":"17FPHxfGII4DKroTYITFj3r4vAmm0NBYH","timestamp":1589393413238}],"collapsed_sections":["Mhgc8dlkL_UT","5Lgaf8JCiI-L"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Bgp1DV4UuWzW","colab_type":"text"},"source":["<font color=\"green\">*To start working on this notebook, or any other notebook that we will use in the Moringa Data Science Course, we will need to save our own copy of it. We can do this by clicking File > Save a Copy in Drive. We will then be able to make edits to our own copy of this notebook.*</font>"]},{"cell_type":"markdown","metadata":{"id":"8flRWHtSHki3","colab_type":"text"},"source":["# Python Programming: Bayes Theorem"]},{"cell_type":"markdown","metadata":{"id":"96w9G0XWJrC3","colab_type":"text"},"source":["The Bayes Theorem is applicable in machine learning where we get to use a Bayes classifier inorder to make a prediction. In this session, we will learn how to apply this classifer to a few machine learning problems even though later during Core we will spent time exhaustively on working on such problems. While working, we should note that the bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature. \n","\n","For example, a fruit may be considered to be an apple if it is red, round, and about 3 inches in diameter. Even if these features depend on each other or upon the existence of the other features, all of these properties independently contribute to the probability that this fruit is an apple and that is why it is known as ‘Naive’.\n","\n","Such classifiers, Naive Bayes classifiers, are a collection of classification algorithms based on Bayes’ Theorem. It is not a single algorithm but a family of algorithms where all of them share a common principle, i.e. every pair of features being classified is independent of each other.\n"]},{"cell_type":"markdown","metadata":{"id":"Mhgc8dlkL_UT","colab_type":"text"},"source":["## Example "]},{"cell_type":"code","metadata":{"id":"9lBLmRc5HgqE","colab_type":"code","colab":{}},"source":["# Example 1\n","# ---\n","# Let's see an overview on how this classifier works, which suitable applications it has, \n","# and how to use it in just a few lines of Python and the Scikit-Learn library.\n","# ---\n","# Question: Build a very simple SPAM detector for SMS messages given the following dataset; \n","# ---\n","# Dataset source = https://archive.ics.uci.edu/ml/datasets/sms+spam+collection\n","#"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GxW80SGJcwPP","colab_type":"code","colab":{}},"source":["# Importing our library\n","# ---\n","#\n","import pandas as pd\n","\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NF7rixbGclp_","colab_type":"code","outputId":"6df75080-35cc-4984-a4a5-b880e9416b22","executionInfo":{"status":"ok","timestamp":1589466232405,"user_tz":-180,"elapsed":2275,"user":{"displayName":"paul mwaura","photoUrl":"","userId":"05571276976991411894"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Loading our uploaded Data\n","# ---\n","# We define a separator (in this case, a tab) and rename the columns accordingly\n","# \n","df = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['label', 'message'], encoding='latin-1')\n","df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  label                                            message\n","0   ham  Go until jurong point, crazy.. Available only ...\n","1   ham                      Ok lar... Joking wif u oni...\n","2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n","3   ham  U dun say so early hor... U c already then say...\n","4   ham  Nah I don't think he goes to usf, he lives aro..."]},"metadata":{"tags":[]},"execution_count":164}]},{"cell_type":"code","metadata":{"id":"cgQU75Rhc2i2","colab_type":"code","outputId":"60ecfe81-6028-40a2-d17c-261d300ff504","executionInfo":{"status":"ok","timestamp":1589466232406,"user_tz":-180,"elapsed":2261,"user":{"displayName":"paul mwaura","photoUrl":"","userId":"05571276976991411894"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Pre-processing\n","# ---\n","# 1. Converting the labels from strings to binary values for our classifier\n","# \n","df['label'] = df.label.map({'ham': 0, 'spam': 1})\n","df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   label                                            message\n","0      0  Go until jurong point, crazy.. Available only ...\n","1      0                      Ok lar... Joking wif u oni...\n","2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n","3      0  U dun say so early hor... U c already then say...\n","4      0  Nah I don't think he goes to usf, he lives aro..."]},"metadata":{"tags":[]},"execution_count":165}]},{"cell_type":"code","metadata":{"id":"MXLkppitgQ7A","colab_type":"code","outputId":"fb79de8a-7403-4e67-e9cb-1f30a81ce1e5","executionInfo":{"status":"ok","timestamp":1589466232407,"user_tz":-180,"elapsed":2245,"user":{"displayName":"paul mwaura","photoUrl":"","userId":"05571276976991411894"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Pre-processing\n","# ---\n","# 2. Converting all characters in the message to lower case:\n","# \n","df['message'] = df.message.map(lambda x: x.lower())\n","df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>go until jurong point, crazy.. available only ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>ok lar... joking wif u oni...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>u dun say so early hor... u c already then say...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>nah i don't think he goes to usf, he lives aro...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   label                                            message\n","0      0  go until jurong point, crazy.. available only ...\n","1      0                      ok lar... joking wif u oni...\n","2      1  free entry in 2 a wkly comp to win fa cup fina...\n","3      0  u dun say so early hor... u c already then say...\n","4      0  nah i don't think he goes to usf, he lives aro..."]},"metadata":{"tags":[]},"execution_count":166}]},{"cell_type":"code","metadata":{"id":"jG3j0ymwgWOx","colab_type":"code","outputId":"f10264b1-07dc-4c14-f244-1e255c4de7b6","executionInfo":{"status":"ok","timestamp":1589466232410,"user_tz":-180,"elapsed":2213,"user":{"displayName":"paul mwaura","photoUrl":"","userId":"05571276976991411894"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Pre-processing\n","# ---\n","# 3. Remove any punctuation:\n","# \n","df['message'] = df.message.str.replace('[^\\w\\s]', '')\n","df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>go until jurong point crazy available only in ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>ok lar joking wif u oni</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>u dun say so early hor u c already then say</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>nah i dont think he goes to usf he lives aroun...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   label                                            message\n","0      0  go until jurong point crazy available only in ...\n","1      0                            ok lar joking wif u oni\n","2      1  free entry in 2 a wkly comp to win fa cup fina...\n","3      0        u dun say so early hor u c already then say\n","4      0  nah i dont think he goes to usf he lives aroun..."]},"metadata":{"tags":[]},"execution_count":167}]},{"cell_type":"code","metadata":{"id":"M0B-lfLPgivV","colab_type":"code","outputId":"90b21330-be47-43bb-89d7-83193ec9d2d2","executionInfo":{"status":"ok","timestamp":1589466232411,"user_tz":-180,"elapsed":2197,"user":{"displayName":"paul mwaura","photoUrl":"","userId":"05571276976991411894"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Pre-processing\n","# ---\n","# 4. tokenize the messages into into single words using nltk. \n","# First, we have to import and download the tokenizer from the console:\n","# \n","import nltk\n","nltk.download(\"popular\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading collection 'popular'\n","[nltk_data]    | \n","[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n","[nltk_data]    |   Package cmudict is already up-to-date!\n","[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n","[nltk_data]    |   Package gazetteers is already up-to-date!\n","[nltk_data]    | Downloading package genesis to /root/nltk_data...\n","[nltk_data]    |   Package genesis is already up-to-date!\n","[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]    |   Package gutenberg is already up-to-date!\n","[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n","[nltk_data]    |   Package inaugural is already up-to-date!\n","[nltk_data]    | Downloading package movie_reviews to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package movie_reviews is already up-to-date!\n","[nltk_data]    | Downloading package names to /root/nltk_data...\n","[nltk_data]    |   Package names is already up-to-date!\n","[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n","[nltk_data]    |   Package shakespeare is already up-to-date!\n","[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n","[nltk_data]    |   Package stopwords is already up-to-date!\n","[nltk_data]    | Downloading package treebank to /root/nltk_data...\n","[nltk_data]    |   Package treebank is already up-to-date!\n","[nltk_data]    | Downloading package twitter_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package twitter_samples is already up-to-date!\n","[nltk_data]    | Downloading package omw to /root/nltk_data...\n","[nltk_data]    |   Package omw is already up-to-date!\n","[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n","[nltk_data]    |   Package wordnet is already up-to-date!\n","[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n","[nltk_data]    |   Package wordnet_ic is already up-to-date!\n","[nltk_data]    | Downloading package words to /root/nltk_data...\n","[nltk_data]    |   Package words is already up-to-date!\n","[nltk_data]    | Downloading package maxent_ne_chunker to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n","[nltk_data]    | Downloading package punkt to /root/nltk_data...\n","[nltk_data]    |   Package punkt is already up-to-date!\n","[nltk_data]    | Downloading package snowball_data to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package snowball_data is already up-to-date!\n","[nltk_data]    | Downloading package averaged_perceptron_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n","[nltk_data]    |       to-date!\n","[nltk_data]    | \n","[nltk_data]  Done downloading collection popular\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":168}]},{"cell_type":"code","metadata":{"id":"0Ttknwa9guS4","colab_type":"code","outputId":"5acc2e8d-6871-4c89-aa06-3990134bbbe5","executionInfo":{"status":"ok","timestamp":1589466232904,"user_tz":-180,"elapsed":2676,"user":{"displayName":"paul mwaura","photoUrl":"","userId":"05571276976991411894"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Pre-processing\n","# ---\n","# 5. Applying the tokenization. \n","# What is tokenization (http://bit.ly/WhatisTokenization)\n","# \n","df['message'] = df['message'].apply(nltk.word_tokenize)\n","df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>[go, until, jurong, point, crazy, available, o...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>[ok, lar, joking, wif, u, oni]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   label                                            message\n","0      0  [go, until, jurong, point, crazy, available, o...\n","1      0                     [ok, lar, joking, wif, u, oni]\n","2      1  [free, entry, in, 2, a, wkly, comp, to, win, f...\n","3      0  [u, dun, say, so, early, hor, u, c, already, t...\n","4      0  [nah, i, dont, think, he, goes, to, usf, he, l..."]},"metadata":{"tags":[]},"execution_count":169}]},{"cell_type":"markdown","metadata":{"id":"wvOJtjodowLb","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"4kWxzerKg0V6","colab_type":"code","outputId":"13c3b11b-08e0-4e80-b384-851ebc6020e6","executionInfo":{"status":"ok","timestamp":1589466234757,"user_tz":-180,"elapsed":4520,"user":{"displayName":"paul mwaura","photoUrl":"","userId":"05571276976991411894"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Pre-processing\n","# ---\n","# 6. We then perform some word stemming. \n","# The idea of stemming is to normalize our text for all variations of words carry the same meaning, \n","# regardless of the tense. One of the most popular stemming algorithms is the Porter Stemmer:\n","# \n","from nltk.stem import PorterStemmer\n","\n","stemmer = PorterStemmer()\n"," \n","df['message'] = df['message'].apply(lambda x: [stemmer.stem(y) for y in x])\n","df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>[go, until, jurong, point, crazi, avail, onli,...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>[ok, lar, joke, wif, u, oni]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>[free, entri, in, 2, a, wkli, comp, to, win, f...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>[u, dun, say, so, earli, hor, u, c, alreadi, t...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>[nah, i, dont, think, he, goe, to, usf, he, li...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   label                                            message\n","0      0  [go, until, jurong, point, crazi, avail, onli,...\n","1      0                       [ok, lar, joke, wif, u, oni]\n","2      1  [free, entri, in, 2, a, wkli, comp, to, win, f...\n","3      0  [u, dun, say, so, earli, hor, u, c, alreadi, t...\n","4      0  [nah, i, dont, think, he, goe, to, usf, he, li..."]},"metadata":{"tags":[]},"execution_count":170}]},{"cell_type":"code","metadata":{"id":"oXv3cwwrhAWw","colab_type":"code","outputId":"0a5c9917-39d9-4fae-f0b8-7427fc473d31","executionInfo":{"status":"ok","timestamp":1589466234767,"user_tz":-180,"elapsed":4520,"user":{"displayName":"paul mwaura","photoUrl":"","userId":"05571276976991411894"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Pre-processing\n","# ---\n","# 7. We will transform the data into occurrences, \n","# which will be the features that we will feed into our model:\n","#\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","# This converts the list of words into space-separated strings\n","df['message'] = df['message'].apply(lambda x: ' '.join(x))\n","\n","count_vect = CountVectorizer()\n","counts = count_vect.fit_transform(df['message'])\n","df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>go until jurong point crazi avail onli in bugi...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>ok lar joke wif u oni</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>free entri in 2 a wkli comp to win fa cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>u dun say so earli hor u c alreadi then say</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>nah i dont think he goe to usf he live around ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   label                                            message\n","0      0  go until jurong point crazi avail onli in bugi...\n","1      0                              ok lar joke wif u oni\n","2      1  free entri in 2 a wkli comp to win fa cup fina...\n","3      0        u dun say so earli hor u c alreadi then say\n","4      0  nah i dont think he goe to usf he live around ..."]},"metadata":{"tags":[]},"execution_count":171}]},{"cell_type":"code","metadata":{"id":"VERkaCMThK8I","colab_type":"code","outputId":"6655dac2-96a0-4aa6-f230-13f11660511f","executionInfo":{"status":"ok","timestamp":1589466234768,"user_tz":-180,"elapsed":4511,"user":{"displayName":"paul mwaura","photoUrl":"","userId":"05571276976991411894"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Pre-processing\n","# ---\n","# 8. We could leave it as the simple word-count per message, \n","# but it is better to use Term Frequency Inverse Document Frequency, more known as tf-idf:\n","#\n","from sklearn.feature_extraction.text import TfidfTransformer\n","\n","transformer = TfidfTransformer().fit(counts)\n","\n","counts = transformer.transform(counts)\n","df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>go until jurong point crazi avail onli in bugi...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>ok lar joke wif u oni</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>free entri in 2 a wkli comp to win fa cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>u dun say so earli hor u c alreadi then say</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>nah i dont think he goe to usf he live around ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   label                                            message\n","0      0  go until jurong point crazi avail onli in bugi...\n","1      0                              ok lar joke wif u oni\n","2      1  free entri in 2 a wkli comp to win fa cup fina...\n","3      0        u dun say so earli hor u c alreadi then say\n","4      0  nah i dont think he goe to usf he live around ..."]},"metadata":{"tags":[]},"execution_count":172}]},{"cell_type":"code","metadata":{"id":"vksf5PobhVQ-","colab_type":"code","colab":{}},"source":["# Training the Model\n","# ---\n","# Now that we have performed feature extraction from our data, \n","# it is time to build our model. We will start by splitting our data into training and test sets:\n","#\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(counts, df['label'], test_size=0.1, random_state=69)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PUWlrPzwhfAb","colab_type":"code","colab":{}},"source":["# Training the Model\n","# ---\n","# Then, all that we have to do is initialize the Naive Bayes Classifier and fit the data. \n","# For text classification problems, the Multinomial Naive Bayes Classifier is well-suited:\n","# \n","from sklearn.naive_bayes import MultinomialNB\n","\n","model = MultinomialNB().fit(X_train, y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DT0zZNSkhpvM","colab_type":"code","outputId":"7c6c9635-2743-4e38-fbd6-b16e0543a34e","executionInfo":{"status":"ok","timestamp":1589466234772,"user_tz":-180,"elapsed":4495,"user":{"displayName":"paul mwaura","photoUrl":"","userId":"05571276976991411894"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Evaluating the Model\n","# ---\n","# Once we have put together our classifier, we can evaluate its performance in the testing set:\n","#\n","predicted = model.predict(X_test)\n","\n","print(np.mean(predicted == y_test))\n","\n","# Our simple Naive Bayes Classifier has 94.8% accuracy with this specific test set!"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.9480286738351255\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5Lgaf8JCiI-L","colab_type":"text"},"source":["## <font color=\"green\">Challenges</font>"]},{"cell_type":"code","metadata":{"id":"8dc0e47upl0q","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LG5nw1kRtU0g","colab_type":"code","outputId":"2760e042-861b-42c0-9c4b-ee9c48419841","executionInfo":{"status":"ok","timestamp":1589466234774,"user_tz":-180,"elapsed":4467,"user":{"displayName":"paul mwaura","photoUrl":"","userId":"05571276976991411894"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Challenge 1\n","# ---\n","# In this challenge, we have been tasked with creating a classifier, the training set,\n","# then training the classifier using the training set and making a prediction.\n","# ---\n","# The training set (X) consits of length, weight and shoe size. \n","# Y contains the associated labels (male or female).\n","# \n","\n","X = [[121, 80, 44], [180, 70, 43], [166, 60, 38], [153, 54, 37], [166, 65, 40], [190, 90, 47], [175, 64, 39],\n","     [174, 71, 40], [159, 52, 37], [171, 76, 42], [183, 85, 43]]\n","\n","Y = ['male', 'male', 'female', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'male']\n","\n","# Training the classifier:\n","#\n","columns = [\"length\", 'weight', \"shoe_size\"]\n","df = pd.DataFrame(X, Y, columns=columns)\n","df.head()\n","\n","# Training the Model\n","# ---\n","# Now that we have performed feature extraction from our data, \n","# it is time to build our model. We will start by splitting our data into training and test sets:\n","#\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(df[['weight', 'length']], df['shoe_size'], test_size=0.3, random_state=69)\n","\n","# Using the GaussianNB classifier (i.e. from sklearn.naive_bayes import GaussianNB) \n","# Training the model\n","#\n","from sklearn.naive_bayes import GaussianNB\n","model = GaussianNB()\n","model.fit(X_train, y_train)\n","\n","# Making the prediciton:\n","# \n","y = model.predict(X_test)\n","print(f\"Predicted shoe sizes are: {y}\")\n","\n","#Import scikit-learn metrics module for accuracy calculation\n","from sklearn import metrics\n","\n","# Model Accuracy, how often is the classifier correct?\n","print(\"Accuracy:\",metrics.accuracy_score(y_test, y))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Predicted shoe sizes are: [40 40 40 43]\n","Accuracy: 0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rHn_lBT8iPVY","colab_type":"code","outputId":"ec255409-a858-48fe-f65f-a2d66108cd65","executionInfo":{"status":"ok","timestamp":1589466287627,"user_tz":-180,"elapsed":1367,"user":{"displayName":"paul mwaura","photoUrl":"","userId":"05571276976991411894"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["# Example 2\n","# ---\n","# Question: Use the titanic disaster dataset to create a Gaussian Naive Bayes classifier model \n","# (i.e. from sklearn.naive_bayes import GaussianNB) that will make a prediction of survival \n","# using passenger ticket fare information. \n","# ---\n","# Dataset url: http://bit.ly/TitanicDataset \n","# \n","train = pd.read_csv(\"train.csv\")\n","test = pd.read_csv(\"test.csv\")\n","\n","train.dropna(inplace=True)\n","test.dropna(inplace=True)\n","\n","X_train, X_test = train_test_split(train[[\"Pclass\", 'Age', 'SibSp', 'Fare']], test_size=0.3, random_state=69)\n","y_train, y_test = train_test_split(train['Sex'], test_size=0.3, random_state=69)\n","\n","\n","\n","from sklearn.naive_bayes import GaussianNB\n","model = GaussianNB()\n","model.fit(X_train, y_train)\n","\n","# Making the prediciton:\n","# \n","y_pred = model.predict(X_test)\n","print(f\"Predicted Titanic are: {y_pred}\")\n","\n","#Import scikit-learn metrics module for accuracy calculation\n","from sklearn import metrics\n","\n","# Model Accuracy, how often is the classifier correct?\n","print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Predicted Titanic are: ['female' 'male' 'female' 'female' 'male' 'female' 'male' 'female' 'male'\n"," 'female' 'male' 'male' 'male' 'male' 'male' 'male' 'female' 'male' 'male'\n"," 'male' 'female' 'male' 'female' 'female' 'female' 'male' 'male' 'male'\n"," 'male' 'female' 'male' 'male' 'male' 'male' 'male' 'male' 'female' 'male'\n"," 'male' 'male' 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'male'\n"," 'female' 'female' 'male' 'female' 'male' 'female' 'male']\n","Accuracy: 0.5454545454545454\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RZizDQj7iQ4O","colab_type":"code","outputId":"253e9d7c-5212-4582-94d9-58e4e00ae311","executionInfo":{"status":"ok","timestamp":1589466289341,"user_tz":-180,"elapsed":2232,"user":{"displayName":"paul mwaura","photoUrl":"","userId":"05571276976991411894"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["# Example 3\n","# ---\n","# Question: Create a GaussianNB classifier (i.e. from sklearn.naive_bayes import GaussianNB) \n","# to identify the different species of iris flowers.\n","# ---\n","# Dataset url = http://bit.ly/MSIrisDatasetNB\n","# \n","iris = pd.read_csv(\"http://bit.ly/MSIrisDatasetNB\")\n","iris.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal_length</th>\n","      <th>sepal_width</th>\n","      <th>petal_length</th>\n","      <th>petal_width</th>\n","      <th>species</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>setosa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>setosa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>setosa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>setosa</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>setosa</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sepal_length  sepal_width  petal_length  petal_width species\n","0           5.1          3.5           1.4          0.2  setosa\n","1           4.9          3.0           1.4          0.2  setosa\n","2           4.7          3.2           1.3          0.2  setosa\n","3           4.6          3.1           1.5          0.2  setosa\n","4           5.0          3.6           1.4          0.2  setosa"]},"metadata":{"tags":[]},"execution_count":183}]},{"cell_type":"code","metadata":{"id":"C7Uo3SVWY5yG","colab_type":"code","outputId":"90845bda-3174-4ba1-9a3b-fd4e320fbb0e","executionInfo":{"status":"ok","timestamp":1589466293630,"user_tz":-180,"elapsed":1525,"user":{"displayName":"paul mwaura","photoUrl":"","userId":"05571276976991411894"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(iris[[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]], iris['species'], test_size=0.3, random_state=69)\n","\n","\n","from sklearn.naive_bayes import GaussianNB\n","model = GaussianNB()\n","model.fit(X_train, y_train)\n","\n","# Making the prediciton:\n","# \n","y = model.predict(X_test)\n","print(f\"Predicted Titanic are: {y}\")\n","\n","#Import scikit-learn metrics module for accuracy calculation\n","from sklearn import metrics\n","\n","# Model Accuracy, how often is the classifier correct?\n","print(\"Accuracy:\",metrics.accuracy_score(y_test, y))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Predicted Titanic are: ['setosa' 'versicolor' 'setosa' 'virginica' 'setosa' 'setosa' 'versicolor'\n"," 'virginica' 'virginica' 'setosa' 'versicolor' 'virginica' 'setosa'\n"," 'versicolor' 'virginica' 'versicolor' 'versicolor' 'virginica'\n"," 'versicolor' 'virginica' 'virginica' 'versicolor' 'setosa' 'setosa'\n"," 'virginica' 'setosa' 'virginica' 'virginica' 'versicolor' 'setosa'\n"," 'setosa' 'setosa' 'setosa' 'virginica' 'virginica' 'virginica' 'setosa'\n"," 'versicolor' 'versicolor' 'virginica' 'setosa' 'virginica' 'versicolor'\n"," 'setosa' 'virginica']\n","Accuracy: 0.9555555555555556\n"],"name":"stdout"}]}]}